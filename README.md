# machine-learning-projects
Config files for my GitHub profile.


1.)   ğŸŒ¿ Medicinal Herbal Plant Identification using Deep Learning
ğŸ“Œ Overview

This project focuses on the automatic identification of medicinal herbal plants using deep learning techniques.
The goal is to build a classification model that can recognize and distinguish between different medicinal plants from images, aiding in research, healthcare, and conservation.

ğŸš€ Features

Image classification of medicinal herbal plants.

Deep Learning models (Transfer Learning like VGG16, EfficientNet).

Trained and evaluated with accuracy, precision, recall, and F1-score.

Deployed in a Jupyter/Google Colab environment for easy usage.

ğŸ“‚ Dataset

Images of medicinal herbal plants collected from open-source datasets.

Preprocessed with resizing, normalization, and augmentation.

Split into training, validation, and testing sets.

ğŸ› ï¸ Tech Stack

Python

TensorFlow / Keras (for building the model)

NumPy, Pandas, Matplotlib (for data handling and visualization)

Google Colab (for training and execution)

âš™ï¸ Model Architecture

Convolutional Neural Network (CNN) with multiple layers.

Transfer Learning (VGG16 / EfficientNet) for improved accuracy.

Optimizer: Adam

Loss Function: Categorical Crossentropy

ğŸ“Š Results

Achieved high accuracy on the test dataset.

Model evaluation includes confusion matrix, precision, recall, and F1-score.

ğŸ”— View Project

You can directly view and run the project on Google Colab here:
ğŸ‘‰ Medicinal Herbal Plant Identification - Google Colab - https://colab.research.google.com/drive/1H3ope7VMOIjUi9INogG6juazNv3nnJO1?usp=sharing


2.)  ğŸ­ Emotion Detection in Video
ğŸ“Œ Overview

This project focuses on detecting human emotions in real-time video using Deep Learning and Computer Vision.
It captures frames from a video, detects faces, and classifies emotions such as happy, sad, angry, surprised, neutral, fear, and disgust.

ğŸš€ Features

Real-time face detection using OpenCV.

Emotion recognition using Deep Learning models.

Supports video input (uploaded video).

Visualizes results by drawing bounding boxes with emotion labels.

ğŸ“‚ Workflow

Upload or stream a video.

Extract frames using OpenCV.

Detect faces in each frame.

Recognize emotions with DeepFace / CNN.

Display results with labeled bounding boxes.

ğŸ› ï¸ Tech Stack

Python

OpenCV (for video and face detection)

DeepFace (for pre-trained emotion detection)

TensorFlow / Keras (for custom models if used)

Matplotlib / Seaborn (for visualization)

ğŸ“Š Results

Emotions detected frame by frame.

Bounding boxes with labels (e.g., Happy ğŸ˜€, Sad ğŸ˜¢, Angry ğŸ˜¡).

Can analyze emotional trends throughout the video.
to view a project as a video : https://drive.google.com/file/d/1fYN30psAeO0NwVd07ElLCMB-CfrmS8Oz/view?usp=drive_link
